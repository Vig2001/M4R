---
title: "Simulation Trials"
author: "Vignesh Balaji"
date: "2024-11-28"
output: html_document
---

# Simulate Power Trials

## Control Group

Set the time limit to be 48 weeks

1. Use the simulated baseline scores above.

2. Hypothesise a treatment decay factor for each transition ($\lambda_{21}$, $\lambda_{20}$, $\lambda_{10}$) for each item - assume that the decay factors are the same for each item to begin with, will have to consider non-uniform eventually. Might be useful to base off the median transition times based off the placebo data.

3. Then use this to simulate the \textbf{final} scores for each item - start with exponential function to give the times of transitions and then compare with the time limit of 48 weeks. So if the time to get to zero 

4. Transform the final scores for each individual using the a) NSAA framework b) PC1 at baseline framework c) Graded Response at baseline framework. This leaves us with a matrix / vector of total scores at the end of the trial.

## Treatment Group

Repeat all the steps as you did for the control group except the treatment effect will be a positive constant multiple of the original decays because it will elongate the time it takes for a patient to transition states.

We now have another vector of total scores at the end of the trial for the treatment group. 

## Power analysis

Perform a t-test on the end vectors for the treatment and control vectors. Repeat this a 1000 times to find a representative statistic of the power of the test. Then repeat over multiple treatment effects and plot a power curve! The one that can give a more powerful test for a given treatment effect is better. This is good because essentially you won't require as many participants which is the main bottleneck of current clinical trials because the disease is rare.

# Constant Effect

In this initial study we assume that the treatment effect is constant, that is to say that the treatment affects each item of the NSAA uniformly.

```{r}
library(readr)
library(tidyverse)
library(FactoMineR)
library(dplyr)
library(caret)
library(factoextra)
library(mirt)
```

One hot encoding function
```{r}
encode <- function(df){
  df_fac <- lapply(df, as.factor)
  onehot <- dummyVars("~ .", data = df_fac, fullRank = FALSE)
  X_enc <- data.frame(predict(onehot, newdata = df_fac))
  # Preserve original row names
  rownames(X_enc) <- rownames(df)
  return(X_enc)
}
```

Simulate baseline scores of the whole cohort

```{r}
set.seed(42)

n_samples <- 260
n_items <- 17

latent_trait <- rnorm(n_samples, mean = 0, sd = 1) # use normal as hypothesised

simulate_scores <- function(latent_trait, n_items) {
  scores <- matrix(0, nrow = length(latent_trait), ncol = n_items)
  for (i in 1:n_items) {
    discrimination <- runif(1, 0.5, 2.0) # beta_1
    thresholds <- sort(runif(2, -2, 2)) # intercept for each state transition
    # logits is a 2 x n matrix (2 because of the two transitions 0->1, 1->2)
    logits <- sapply(latent_trait, function(theta) discrimination * theta - thresholds)
    # assign probs based off formula for GRM
    # probs is an n x 2 matrix
    probs <- t(apply(logits, 2, function(x) cumsum(exp(x) / (1 + sum(exp(x))))))
    scores[, i] <- apply(probs, 1, function(p) sum(runif(1) > p))
  }
  return(as.data.frame(scores))
}

item_scores <- simulate_scores(latent_trait, n_items)
colnames(item_scores) <- paste0("Item", 1:n_items)
```

Split the baseline scores into a control and treatment group. In practise this would be done randomly but here we assign the first half to control.

```{r}
num_rows <- nrow(item_scores)
ctrl_grp_base <- item_scores[1:floor(num_rows / 2), ]
treat_grp_base <- item_scores[(floor(num_rows / 2) + 1):num_rows, ]

# assign decay factors based off the trial duration being a year
l_10 <- 0.4
l_21 <- 0.6
l_20 <- 0.2

# recursive survival function
simulate_decay <- function(current_state, l10, l21, l20, total_time, trial_time){
  # base case
  if (total_time >= trial_time){
    return(current_state)
  }
  
  # current_state = 0
  if (current_state == 0){
    return(0)
  }
  # current_state = 1
  else if (current_state == 1){
    t10 = rexp(1, l10)
    total_time <- total_time + t10
    
    if (total_time <= trial_time){
      return(simulate_decay(0, l10, l21, l20, total_time, trial_time))
    }
    else {
      return(1)
    }
  }
  # current_state = 2
  else {
    t21 = rexp(1, l21)
    t20 = rexp(1, l20)
    if (t20 <= t21){
      total_time <- total_time + t20
      return(simulate_decay(0, l10, l21, l20, total_time, trial_time))
    }
    else{
      total_time <- total_time + t21
      return(simulate_decay(1, l10, l21, l20, total_time, trial_time))
    }
  }
}

# apply column wise to get ctrl_grp_end
ctrl_grp_end <- as.data.frame(apply(ctrl_grp_base, 2, function(col){
  sapply(col, function(state) simulate_decay(state, l_10, l_21, l_20, 0, 1))
}))

# this is wrong we need to choose different rates for treatment effect you idiot
treat_grp_end <- as.data.frame(apply(treat_grp_base, 2, function(col){
  sapply(col, function(state) simulate_decay(state, l_10, l_21, l_20, 0, 1))
}))
```

Transform using NSAA and getting PC1 from the one-hot - I guess two things here we either get PC1 from each group separately or we get a universal PC1 from the entire group. I think it makes sense to get it from each group separately.
```{r}
# NSAA transformation - add up each item score individually
ctrl_scores_nsaa <- as.matrix(ctrl_grp_end) %*% rep(1, times = ncol(ctrl_grp_end))
treat_scores_nsaa <- as.matrix(treat_grp_end) %*% rep(1, times = ncol(treat_grp_end))

ctrl_pca <- prcomp(encode(ctrl_grp_base), scale. = T)

treat_pca <- prcomp(encode(treat_grp_base), scale. = T)
treat_pc1 <- treat_pca$rotation[ ,"PC1"]

ctrl_pc1_reg <- ctrl_pc1[names(ctrl_pc1) %in% colnames(encode(ctrl_grp_end))]
treat_pc1_reg <- ctrl_pc1[names(treat_pc1) %in% colnames(encode(treat_grp_end))]

ctrl_scores_pc1 <- as.matrix(encode(ctrl_grp_end)) %*% ctrl_pc1_reg
treat_scores_pc1 <- as.matrix(encode(treat_grp_end)) %*% treat_pc1_reg

t.test(ctrl_scores_pc1, treat_scores_pc1)
t.test(ctrl_scores_nsaa, treat_scores_nsaa)
```