---
title: "Simulation Trials"
author: "Vignesh Balaji"
date: "2024-11-28"
output: html_document
---

# Simulate Power Trials

## Control Group

Set the time limit to be 48 weeks

1. Use the simulated baseline scores above.

2. Hypothesise a treatment decay factor for each transition ($\lambda_{21}$, $\lambda_{20}$, $\lambda_{10}$) for each item - assume that the decay factors are the same for each item to begin with, will have to consider non-uniform eventually. Might be useful to base off the median transition times based off the placebo data.

3. Then use this to simulate the \textbf{final} scores for each item - start with exponential function to give the times of transitions and then compare with the time limit of 48 weeks. So if the time to get to zero 

4. Transform the final scores for each individual using the a) NSAA framework b) PC1 at baseline framework c) Graded Response at baseline framework. This leaves us with a matrix / vector of total scores at the end of the trial.

## Treatment Group

Repeat all the steps as you did for the control group except the treatment effect will be a positive constant multiple of the original decays because it will elongate the time it takes for a patient to transition states.

We now have another vector of total scores at the end of the trial for the treatment group. 

## Power analysis

Perform a t-test on the end vectors for the treatment and control vectors. Repeat this a 1000 times to find a representative statistic of the power of the test. Then repeat over multiple treatment effects and plot a power curve! The one that can give a more powerful test for a given treatment effect is better. This is good because essentially you won't require as many participants which is the main bottleneck of current clinical trials because the disease is rare.

# Constant Effect

In this initial study we assume that the treatment effect is constant, that is to say that the treatment affects each item of the NSAA uniformly.

```{r}
library(readr)
library(tidyverse)
library(FactoMineR)
library(dplyr)
library(caret)
library(fastDummies)
library(factoextra)
library(mirt)
```

One hot encoding function
```{r}
encode <- function(df){
  df_fac <- lapply(df, as.factor)
  df_enc <- dummy_cols(
    df_fac,
    remove_first_dummy = F,
    remove_selected_columns = T
  )
  colnames(df_enc) <- gsub("^\\.data\\.", "", colnames(df_enc))
  colnames(df_enc) <- gsub("_", ".", colnames(df_enc))
  return(df_enc)
}
```

Simulate baseline scores of the whole cohort
```{r}
set.seed(42)

n_samples <- 260
n_items <- 17

latent_trait <- rnorm(n_samples, mean = 0, sd = 1) # use normal as hypothesised

simulate_scores <- function(latent_trait, n_items) {
  scores <- matrix(0, nrow = length(latent_trait), ncol = n_items)
  discrimination_params <- numeric(n_items)
  thresholds_list <- list()
  
  for (i in 1:n_items) {
    discrimination <- runif(1, 0.1, 2.0) # 'a' parameter
    thresholds <- sort(runif(2, -2, 2))   # 'b' parameters (thresholds)
    
    discrimination_params[i] <- discrimination
    thresholds_list[[i]] <- thresholds
    
    for (j in 1:length(latent_trait)) {
      theta <- latent_trait[j]
      # cumulative probabilities (logistic function)
      P_Y_geq_1 <- 1 / (1 + exp(-discrimination * (theta - thresholds[1])))
      P_Y_geq_2 <- 1 / (1 + exp(-discrimination * (theta - thresholds[2])))
      
      # state probabilities
      P0 <- 1 - P_Y_geq_1
      P1 <- P_Y_geq_1 - P_Y_geq_2
      P2 <- P_Y_geq_2
      
      probs <- c(P0, P1, P2)
      # sampling scores (n_samples x n_items)
      scores[j, i] <- sample(0:2, size = 1, prob = probs)
    }
  }
  
  # return dataframe, discrimination and threshold params for future ref
  list(
    scores = as.data.frame(scores), 
    discrimination_params = discrimination_params,
    thresholds = thresholds_list
  )
}

result <- simulate_scores(latent_trait, n_items)

item_scores <- result$scores
colnames(item_scores) <- paste0("Item", 1:n_items)

discrimination_params <- result$discrimination_params

thresholds <- result$thresholds

# find the most important items - this might come in handy later on when assigning treatment effect non-uniformly
barplot(discrimination_params, 
        main = "Discrimination Parameters (β1)", 
        xlab = "Items", 
        ylab = "Discrimination (β1)", 
        names.arg = paste0("Item", 1:n_items), 
        col = "blue")

# identify item difficulty based on thresholds
threshold_means <- sapply(thresholds, mean) 
difficulty_order <- order(threshold_means, decreasing = TRUE) 

data.frame(
  Item = paste0("Item", 1:n_items),
  Mean_Threshold = threshold_means
)[difficulty_order, ]

```

Split the baseline scores into a control and treatment group. In practise this would be done randomly but here we assign the first half to control. Then assign decay rates based off the difficulty of each item which is given by the threshold parameter used to generate the data.

```{r}
num_rows <- nrow(item_scores)
ctrl_grp_base <- item_scores[1:floor(num_rows / 2), ]
treat_grp_base <- item_scores[(floor(num_rows / 2) + 1):num_rows, ]

# assign decay factors based off the trial duration being a year
rate_21 <- 0.8
rate_10 <- 1.6
rate_20 <- 0.4

# Shift thresholds to make all values positive
shift_constant <- abs(min(unlist(thresholds))) + 1
shifted_thresholds <- lapply(thresholds, function(t) t + shift_constant)
threshold_means <- sapply(shifted_thresholds, mean)

# Generate decay rates proportional to shifted thresholds
decay_rates <- sapply(threshold_means, function(mean_thresh) {
  c(l_21 = mean_thresh * rate_21, 
    l_10 = mean_thresh * rate_10, 
    l_20 = mean_thresh * rate_20)
})
decay_rates <- t(decay_rates)

decay_rates_df <- data.frame(
  l_21 = decay_rates[, 1],
  l_10 = decay_rates[, 2],
  l_20 = decay_rates[, 3]
)

rownames(decay_rates_df) = paste0("Item", 1:n_items)
```


```{r}
# recursive survival function
simulate_decay <- function(current_state, l10, l21, l20, total_time, trial_time) {
  
  # state transitions
  if (current_state == 0) {
    return(0)
  } else if (current_state == 1) {
    # Transition from state 1 to 0
    t10 <- rexp(1, l10)
    total_time <- total_time + t10
    if (total_time <= trial_time) {
      return(simulate_decay(0, l10, l21, l20, total_time, trial_time))
    } else {
      return(1)
    }
  } else if (current_state == 2) {
    # transition from state 2 to either 1 or 0
    t21 <- rexp(1, l21)
    t20 <- rexp(1, l20)
    if (t20 <= t21) {
      total_time <- total_time + t20
      if (total_time <= trial_time) {
        return(simulate_decay(0, l10, l21, l20, total_time, trial_time))
      } else {
        return(2)
      }
    } else {
      total_time <- total_time + t21
      if (total_time <= trial_time) {
        return(simulate_decay(1, l10, l21, l20, total_time, trial_time))
      } else {
        return(2)
      }
    }
  }
}


# apply column wise to get ctrl_grp_end
ctrl_grp_end <- as.data.frame(apply(ctrl_grp_base, 2, function(col){
  sapply(col, 
         function(state) simulate_decay(state, decay_rates_df[col, 1],
                                        decay_rates_df[col, 2], 
                                        decay_rates_df[col, 3], 0, 1))
}))


# treatment effect
teff = 1.6

treat_grp_end <- as.data.frame(apply(treat_grp_base, 2, function(col){
  sapply(col, 
         function(state) simulate_decay(state, decay_rates_df[col, 1]/teff,
                                        decay_rates_df[col, 2]/teff, 
                                        decay_rates_df[col, 3]/teff, 0, 1))
}))
```

Transform scores using NSAA, PCA and IRT frameworks.
```{r}
scoring_method <- function(score, base = TRUE, ctrl = TRUE) {
  
  # get correct subset of data
  get_data <- function(base, ctrl) {
    if (ctrl) {
      if (base) return(ctrl_grp_base)
      else return(ctrl_grp_end)
    } else {
      if (base) return(treat_grp_base)
      else return(treat_grp_end)
    }
  }
  
  # NSAA helper
  basic_sums <- function(base, ctrl) {
    data <- get_data(base, ctrl)
    return(rowSums(data))
  }
  
  # PCA helper
  do_pca <- function(base, ctrl) {
    # 52 items
    combined <- rbind(ctrl_grp_base, ctrl_grp_end)
    # PCA
    pca_res <- prcomp(encode(combined), scale. = TRUE)
    pc1 <- pca_res$rotation[, "PC1"]

    subset_data <- encode(get_data(base, ctrl))
    pc1_scores <- as.matrix(subset_data) %*% pc1[colnames(subset_data)]
    return(pc1_scores)
  }
  
  # IRT helper
  do_irt <- function(base, ctrl) {
    # base the weights off the whole baseline data
    base_data <- item_scores
    
    invisible(capture.output({
      suppressWarnings(suppressMessages({
        grm <- mirt(base_data, 1, itemtype = "graded")
      }))
    }))
    weights <- coef(grm, IRTpars = TRUE)
    item_names <- colnames(base_data)
    # irt weights are based off the discrimination parameter a
    irt_weights <- sapply(item_names, function(item) weights[[item]][, "a"])
    subset_data <- get_data(base, ctrl)
    irt_scores <- as.matrix(subset_data) %*% irt_weights[colnames(subset_data)]
    
    # return weights so that we can compare with discrimination_params
    return(list(scores = irt_scores, weights = irt_weights))
  }
  
  # Main logic using switch. Order of conditions matters:
  # We handle "score" first, and within each branch, handle ctrl/base as
  # needed.
  # Note that once we return, the function exits; no need for multiple returns
  # at the end.
  
  result <- switch(score,
    "NSAA" = basic_sums(base, ctrl),
    "PCA"  = do_pca(base, ctrl),
    "IRT"  = do_irt(base, ctrl),
    # Default case: if unknown score, just return basic sums
    basic_sums(base, ctrl)
  )
  
  return(result)
}

ctrl_nsaa_base <- scoring_method("NSAA")
ctrl_nsaa_end <- scoring_method("NSAA", base = F)
treat_nsaa_base <- scoring_method("NSAA", ctrl = F)
treat_nsaa_end <- scoring_method("NSAA", base = F, ctrl = F)

ctrl_pc1_base <- scoring_method("PCA")
ctrl_pc1_end <- scoring_method("PCA", base = F)
treat_pc1_base <- scoring_method("PCA", ctrl = F)
treat_pc1_end <- scoring_method("PCA", base = F, ctrl = F)

ctrl_irt_base <-scoring_method("IRT")$scores
ctrl_irt_end <- scoring_method("IRT", base = F)$scores
treat_irt_base <- scoring_method("IRT", ctrl = F)$scores
treat_irt_end <- scoring_method("IRT", base = F, ctrl = F)$scores
```

An issue that I had above was that one particular item score wasn't visible at baseline but was visible at the end. As a quick fix, I combined control group datasets so that PC1 and IRT weights had 52 dimensions i.e. all the one-hot encoded columns. 

You have to do 1000 simulations and fit a linear model control for baseline {NSAA, PC1, GRM_weights} i.e. end = base*treatment + const. Then calculate power!

```{r}
nsaa_data <- data.frame(
  Score = c(ctrl_nsaa_base, ctrl_nsaa_end, treat_nsaa_base, treat_nsaa_end),
  Group = factor(c(rep(0, length(ctrl_nsaa_base)),
                    rep(0, length(ctrl_nsaa_end)),
                    rep(1, length(treat_nsaa_base)),
                    rep(1, length(treat_nsaa_end)))),
  Time = factor(c(rep(0, length(ctrl_nsaa_base)),
                   rep(1, length(ctrl_nsaa_end)),
                   rep(0, length(treat_nsaa_base)),
                   rep(1, length(treat_nsaa_end))))
)

lm_nsaa <- lm(Score ~ Group * Time, data = nsaa_data)
nsaa_summary <- summary(lm_nsaa)

pca_data <- data.frame(
  Score = c(ctrl_pc1_base, ctrl_pc1_end, treat_pc1_base, treat_pc1_end),
  Group = factor(c(rep(0, length(ctrl_pc1_base)),
                    rep(0, length(ctrl_pc1_end)),
                    rep(1, length(treat_pc1_base)),
                    rep(1, length(treat_pc1_end)))),
  Time = factor(c(rep(0, length(ctrl_pc1_base)),
                   rep(1, length(ctrl_pc1_end)),
                   rep(0, length(treat_pc1_base)),
                   rep(1, length(treat_pc1_end))))
)

lm_pca <- lm(Score ~ Group * Time, data = pca_data)
pca_summary <- summary(lm_pca)

irt_data <- data.frame(
  Score = c(ctrl_irt_base, ctrl_irt_end, treat_irt_base, treat_irt_end),
  Group = factor(c(rep(0, length(ctrl_irt_base)),
                    rep(0, length(ctrl_irt_end)),
                    rep(1, length(treat_irt_base)),
                    rep(1, length(treat_irt_end)))),
  Time = factor(c(rep(0, length(ctrl_irt_base)),
                   rep(1, length(ctrl_irt_end)),
                   rep(0, length(treat_irt_base)),
                   rep(1, length(treat_irt_end))))
)

lm_irt <- lm(Score ~ Group * Time, data = irt_data)
irt_summary <- summary(lm_irt)
```

To calculate the power of the test you find the estimated effect size given by the coefficient of Group1:Time1, the residual standard error which is seen at the bottom of the summary, the sample size and then put into the power.t.test function.

```{r}
power_calc <- function(score_summary, grp_size){
  score_means <- score_summary$coefficients["Group1:Time1", "Estimate"]
  score_sd <- score_summary$sigma
  power_est <- power.t.test(n = grp_size, delta = score_means / score_sd, 
                             sd = score_sd, sig.level = 0.05, 
                             type = "two.sample", 
                             alternative = "two.sided")$power
  return(power_est)
}

nsaa_power <- power_calc(nsaa_summary, 130)
pca_power <- power_calc(pca_summary, 130)
irt_power <- power_calc(irt_summary, 130)

print(nsaa_power)
print(pca_power)
print(irt_power)
```

PCA greatly outperforms the NSAA, which slightly outperforms the IRT in this one specific realisation. I need to test for multiple treatment effects and perform a bootstrap analysis to be sure. The mirt function fails to accurately estimate the dsicrimination parameters - a lot of them are quite far off! This might be because of scale indeterminancy - the small sample size means that the mirt package doesn't choose a scale that actually matches the latent N(0,1) variable. However, the poor performance of IRT could be random variation.

Next steps:
1. For a chosen teff simulate the decay of the baseline scores
2. Attain a bootstrap sample of this data and perform all the steps to calculate the power
3. Do step 2 ~ 1000 times to get an aggregrate power estimate
4. Change the teff (i.e. loop over the teff)
5. Plot the power curves by teff

Then potentially look into how the power changes with sample size for each scoring system.

Below we define the bootstrap-compatible scoring function adapted from above - only change is that it takes in the datasets as input. Note that during boot iterations the sampled datasets will change!
```{r}
scoring_boot <- function(score, ctrl_grp_base, ctrl_grp_end, treat_grp_base, treat_grp_end, base = TRUE, ctrl = TRUE) {
  
  # get correct subset of data
  get_data <- function(base, ctrl) {
    if (ctrl) {
      if (base) return(ctrl_grp_base)
      else return(ctrl_grp_end)
    } else {
      if (base) return(treat_grp_base)
      else return(treat_grp_end)
    }
  }
  
  # NSAA helper
  basic_sums <- function(base, ctrl) {
    data <- get_data(base, ctrl)
    return(rowSums(data))
  }
  
  # PCA helper
  do_pca <- function(base, ctrl) {

    combined <- rbind(ctrl_grp_base, ctrl_grp_end)

    pca_res <- prcomp(encode(combined), scale. = TRUE)
    pc1 <- pca_res$rotation[, "PC1"]

    subset_data <- encode(get_data(base, ctrl))
    pc1_scores <- as.matrix(subset_data) %*% pc1[colnames(subset_data)]
    return(pc1_scores)
  }
  
  # IRT helper
  do_irt <- function(base, ctrl) {

    base_data <- item_scores
    # stop outputs - overwhelming with multiple iterations
    invisible(capture.output({
      suppressWarnings(suppressMessages({
        grm <- mirt(base_data, 1, itemtype = "graded")
      }))
    }))
    weights <- coef(grm, IRTpars = TRUE)
    item_names <- colnames(base_data)
    irt_weights <- sapply(item_names, function(item) weights[[item]][, "a"])
    subset_data <- get_data(base, ctrl)
    irt_scores <- as.matrix(subset_data) %*% irt_weights[colnames(subset_data)]
    
    return(list(scores = irt_scores, weights = irt_weights))
  }
  
  result <- switch(score,
    "NSAA" = basic_sums(base, ctrl),
    "PCA"  = do_pca(base, ctrl),
    "IRT"  = do_irt(base, ctrl),
    basic_sums(base, ctrl)
  )
  
  return(result)
}
```

```{r}
num_boots <- 50
teffs <- seq(1.1, 1.6, length.out=5)
scoring_methods <- c("NSAA", "PCA", "IRT")

# placeholder for eventual dataframe
power_mat <- matrix(NA, nrow = length(teffs), ncol = length(scoring_methods))
rownames(power_mat) <- teffs
colnames(power_mat) <- scoring_methods

# we do not resimulate the baseline scores everytime
# this means we can use the decay rates from decay_rates_df
# also we bypass issue of potentially different baseline columns (recall issue we had with only 50 columns being visualised at baseline instead of 51)

for (teff_idx in seq_along(teffs)){
  # loop over scoring methods as well
  teff <- teffs[teff_idx]
  for (method in scoring_methods){
    # initiliase num_boots vector to store power vals
    power_iter <- numeric(num_boots)
    for (i in 1:num_boots){
      # 1. randomly sample 260 patients from item_scores
      sample_incides <- sample(1:num_rows, size = num_rows, replace = T)
      sample_df <- item_scores[sample_incides, ]
      # 2. split the dataset in half so that we have a control and treat group
      ctrlsample_base <- sample_df[1:floor(num_rows / 2), ]
      treatsample_base <- sample_df[(floor(num_rows / 2) + 1):num_rows, ]
      # 3. simulate decays using teff, method and global var decay_rates_df
      ctrlsample_end <- as.data.frame(apply(ctrlsample_base, 2, function(col){
        sapply(col, 
               function(state) simulate_decay(state, decay_rates_df[col, 1],
                                              decay_rates_df[col, 2],
                                              decay_rates_df[col, 3], 0, 1))
        }))
      treatsample_end <- as.data.frame(apply(treatsample_base, 2,
                                             function(col){
        sapply(col,
               function(state) simulate_decay(state, decay_rates_df[col, 1],
                                              decay_rates_df[col, 2],
                                              decay_rates_df[col, 3], 0, 1))
      }))
      # 4. transform the scores using the scoring method
      # if method = IRT you need to get the scores from the output
      if (method == "IRT"){
              ctrl_base <- scoring_boot(method, ctrlsample_base,
                                        ctrlsample_end,
                                        treatsample_base, 
                                        treatsample_end)$scores
              
              ctrl_end <- scoring_boot(method, ctrlsample_base, 
                                       ctrlsample_end, treatsample_base,
                                       treatsample_end, 
                                       base = F)$scores
              
              treat_base <- scoring_boot(method, ctrlsample_base,
                                         ctrlsample_end, treatsample_base, 
                                         treatsample_end, 
                                         ctrl = F)$scores
              
              treat_end <- scoring_boot(method, ctrlsample_base, 
                                        ctrlsample_end, treatsample_base, 
                                        treatsample_end, base = F,
                                        ctrl = F)$scores
      }
      # else no need
      else{
              ctrl_base <- scoring_boot(method, ctrlsample_base,
                                        ctrlsample_end,
                                        treatsample_base, treatsample_end)
              ctrl_end <- scoring_boot(method, ctrlsample_base, 
                                       ctrlsample_end, treatsample_base, 
                                       treatsample_end, base = F)
              treat_base <- scoring_boot(method, ctrlsample_base,
                                         ctrlsample_end, treatsample_base, 
                                         treatsample_end, ctrl = F)
              treat_end <- scoring_boot(method, ctrlsample_base, 
                                        ctrlsample_end, treatsample_base, 
                                        treatsample_end,
                                        base = F, ctrl = F)
      }

      # 5. Create dataframe to fit lm to
      boot_data <- data.frame(
        Score = c(ctrl_base, ctrl_end, treat_base, 
                  treat_end),
        Group = factor(c(rep(0, length(ctrl_base)),
                         rep(0, length(ctrl_end)),
                         rep(1, length(treat_base)),
                         rep(1, length(treat_end)))),
        Time = factor(c(rep(0, length(ctrl_base)),
                        rep(1, length(ctrl_end)),
                        rep(0, length(treat_base)),
                        rep(1, length(treat_end)))))

      # 6. fit lm and get summary
      lm_boot <- lm(Score ~ Group * Time, data = boot_data)
      bootlm_summary <- summary(lm_boot)
      # 7. calculate power
      power_iter[i] <- power_calc(bootlm_summary, 130)
    }
    power_mat[teff_idx, method] <- mean(power_iter)
  }
}
```

```{r}
print(power_mat)
```

Parallel computing for speed - get Chris to see if he can do this!
```{r}
library(doParallel)
library(foreach)

# Set up parallel backend
num_cores <- parallel::detectCores() - 1
cl <- makeCluster(num_cores)
registerDoParallel(cl)

# Load all libraries on each core
clusterEvalQ(cl, {
  library(readr)
  library(tidyverse)
  library(FactoMineR)
  library(dplyr)
  library(caret)
  library(fastDummies)
  library(factoextra)
  library(mirt)
})

# Export required functions and variables to each core
clusterExport(cl, c("simulate_decay", "scoring_boot", "power_calc"))

# Placeholder for eventual dataframe
power_mat <- matrix(NA, nrow = length(teffs), ncol = length(scoring_methods))
rownames(power_mat) <- teffs
colnames(power_mat) <- scoring_methods

# We do not resimulate the baseline scores every time
# This means we can use the decay rates from decay_rates_df
# Also we bypass the issue of potentially different baseline columns (recall issue we had with only 50 columns being visualized at baseline instead of 51)

# Precompute bootstrap samples
set.seed(123)  # For reproducibility
bootstrap_samples <- replicate(num_boots, sample(1:num_rows, size = num_rows, replace = TRUE), simplify = FALSE)

# Parallelize over treatment effects
power_results <- foreach(teff_idx = seq_along(teffs), .combine = rbind, .packages = c("dplyr")) %dopar% {
  teff <- teffs[teff_idx]

  # Use sapply to loop over methods
  method_power <- sapply(scoring_methods, function(method) {
    # Initialize vector to store power values for each bootstrap
    power_iter <- numeric(num_boots)

    for (i in seq_len(num_boots)) {
      # 1. Randomly sample 260 patients from item_scores
      sample_indices <- bootstrap_samples[[i]]
      sample_df <- item_scores[sample_indices, ]

      # 2. Split the dataset in half so that we have a control and treatment
      # group
      ctrlsample_base <- sample_df[1:floor(num_rows / 2), ]
      treatsample_base <- sample_df[(floor(num_rows / 2) + 1):num_rows, ]

      # 3. Simulate decays using teff, method, and global variable
      # decay_rates_df
      ctrlsample_end <- as.data.frame(apply(ctrlsample_base, 2, function(col) {
        sapply(col, function(state) simulate_decay(state, decay_rates_df[col, 1], decay_rates_df[col, 2], decay_rates_df[col, 3], 0, 1))
      }))

      treatsample_end <- as.data.frame(apply(treatsample_base, 2, function(col) {
        sapply(col, function(state) simulate_decay(state, decay_rates_df[col, 1], decay_rates_df[col, 2], decay_rates_df[col, 3], 0, 1))
      }))

      # 4. Transform the scores using the scoring method
      # If method = IRT, you need to get the scores from the output
      if (method == "IRT") {
        ctrl_base <- scoring_boot(method, ctrlsample_base, 
                                  ctrlsample_end, treatsample_base, 
                                  treatsample_end)$scores
        ctrl_end <- scoring_boot(method, ctrlsample_base, ctrlsample_end, 
                                 treatsample_base, treatsample_end, 
                                 base = FALSE)$scores
        treat_base <- scoring_boot(method, ctrlsample_base, ctrlsample_end, 
                                   treatsample_base, treatsample_end,
                                   ctrl = FALSE)$scores
        treat_end <- scoring_boot(method, ctrlsample_base, ctrlsample_end, 
                                  treatsample_base, treatsample_end,
                                  base = FALSE, ctrl = FALSE)$scores
      } else {
        ctrl_base <- scoring_boot(method, ctrlsample_base, ctrlsample_end, 
                                  treatsample_base, treatsample_end)
        ctrl_end <- scoring_boot(method, ctrlsample_base, ctrlsample_end, 
                                 treatsample_base, treatsample_end, 
                                 base = FALSE)
        treat_base <- scoring_boot(method, ctrlsample_base, ctrlsample_end, 
                                   treatsample_base, treatsample_end, 
                                   ctrl = FALSE)
        treat_end <- scoring_boot(method, ctrlsample_base, ctrlsample_end, 
                                  treatsample_base, treatsample_end, 
                                  base = FALSE, ctrl = FALSE)
      }

      # 5. Create dataframe to fit lm to
      boot_data <- data.frame(
        Score = c(ctrl_base, ctrl_end, treat_base, treat_end),
        Group = factor(c(rep(0, length(ctrl_base)), 
                         rep(0, length(ctrl_end)), 
                         rep(1, length(treat_base)), 
                         rep(1, length(treat_end)))),
        Time = factor(c(rep(0, length(ctrl_base)), 
                        rep(1, length(ctrl_end)), 
                        rep(0, length(treat_base)), 
                        rep(1, length(treat_end))))
      )

      # 6. Fit lm and get summary
      lm_boot <- lm(Score ~ Group * Time, data = boot_data)
      bootlm_summary <- summary(lm_boot)

      # 7. Calculate power
      power_iter[i] <- power_calc(bootlm_summary, 130)
    }

    # Calculate and return average power for the method
    mean(power_iter)
  })

  return(method_power)
}

# Store power results in matrix
power_mat[] <- power_results

# Stop the parallel backend
stopCluster(cl)

# Display the power matrix
print(power_mat)
```